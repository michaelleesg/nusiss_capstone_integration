% ===== Agent B: Historical Entity & Vectorization Agent (HEVA) =====
\agentsectiongap
\begin{agentbox}
\textbf{Agent B – Historical Entity \& Vectorization Agent (HEVA)}\\
\textit{Role:} Converts unstructured threat data into structured vectorized knowledge.\\
\textit{Primary Function:} Acts as the historical memory of CyberSage for retrieval and contextualization.
\end{agentbox}

\section{Historical Entity \& Vectorization Agent (HEVA)}
\label{sec:agentB-heva}

\noindent
Building on the normalized artifacts produced by Agent~A, the \textbf{Historical Entity \& Vectorization Agent (HEVA)} extends CyberSage’s workflow from transient data processing to durable knowledge retention.  
HEVA encodes every parsed observation into a searchable historical record—linking structured metadata with vectorized embeddings—to support future recall, comparison, and reasoning.

\subsection{Problem Motivation}
While Agent~A ensures data quality and schema consistency, it does not retain historical memory once data has been processed.  
For Security Operations Centers (SOCs), this poses a challenge: threat patterns and actor behaviors often recur over weeks or months, and correlating new events with prior observations requires persistent storage.  
HEVA addresses this by converting unstructured CTI text into retrievable records that capture both semantic context and explicit identifiers such as CVEs, affected products, and ATT\&CK techniques.  
Conventional NER models perform poorly on cybersecurity jargon and symbolic identifiers~\cite{devlin2018bert, liu2019roberta, jehangir2023ner, keraghel2024ner}; thus, HEVA employs a hybrid NER and vectorization pipeline to build a historical index that can be efficiently searched and reused across the CyberSage ecosystem.


\textbf{Motivation for Vector Storage.}
Rather than treating entity extraction as an end point, CyberSage persistently stores sentence-level representations in a vector database (Qdrant). This turns HEVA into a living knowledge base: each vector encodes semantic context around CVEs, products, and techniques. When new threat reports arrive, downstream Agent~C performs similarity search over these historical embeddings to ground its large-language-model (LLM) reasoning. HEVA thus functions as both an NER model and a long-term memory substrate for Retrieval-Augmented Generation (RAG).

\subsection{Design and Implementation}
\textbf{Design.}
HEVA acts as the \emph{historical memory} of CyberSage, transforming past Agent~A scrapes into sentence-level embeddings persisted in a Qdrant collection. This enables time-aware retrieval for Agent~C.

\textbf{Implementation.}
HEVA ingests normalized threat artifacts from Agent~A, segments them into sentences using spaCy, and performs a \emph{hybrid Named-Entity-Recognition (NER)} step combining deterministic regex matchers (for CVE, IP, URL, and email patterns) with spaCy’s statistical entity model.  
Extracted entities are merged and emitted as BIO-tagged sentences, then encoded into 384-dimensional embeddings using \texttt{SentenceTransformer} (\texttt{all-MiniLM-L6-v2}).  
Each embedded sentence is persisted to a Qdrant collection via \emph{upsert}, along with payload metadata—\texttt{text}, \texttt{tokens}, \texttt{tags}, \texttt{length}, \texttt{source}, and \texttt{model\_name}.  
A lightweight FastAPI microservice exposes this collection through a \texttt{/search} endpoint, enabling Agent~C to retrieve semantically similar historical evidence for contextual triage.

\begin{lstlisting}[language=json,caption={Qdrant Payload Schema for HEVA (Per Sentence)},label={lst:agentB-payload}]
{
  "text": "CVE-2025-12345 allows RCE in WidgetOS 5.2",
  "tokens": ["CVE-2025-12345","allows","RCE","in","WidgetOS","5.2"],
  "tags": ["CVE","PRODUCT","VERSION","RISK"],
  "length": 7,
  "source": "vendor_blog",
  "created_at": "2025-10-01T08:31:00Z",
  "embedding_model": "all-MiniLM-L6-v2",
  "model_sha": "f13a4c0b72ab",
  "text_sha": "4a0f...e9"
}
\end{lstlisting}

\subsection{Interface}
A FastAPI service (\texttt{/search}) computes a query embedding (same model) and returns the top-$k$ nearest sentences from Qdrant:
\begin{lstlisting}[language=json,caption={/search Response Schema}]
{
  "query": "...",
  "results": [{
    "text": "...",
    "tokens": ["..."],
    "labels": ["..."],
    "tags": ["..."],
    "score": 0.87
  }, ...]
}
\end{lstlisting}
Default $k=5$ (configurable).  
Past evidence remains retrievable with provenance and versioned metadata, supporting reproducibility and audit.

\subsection{Labeling Schema}
The CyberSage-HEVA agent adopts a CTI-oriented label schema aligned with SOC workflows:
\begin{itemize}
    \item \textbf{Identifiers:} CVE\_ID, CWE\_ID, CPE
    \item \textbf{Entities:} PRODUCT, VENDOR, VERSION
    \item \textbf{Threats:} MALWARE, ACTOR, IOC (IP, domain, hash)
    \item \textbf{Tactics/Techniques:} ATTACK\_TECHNIQUE (mapped to MITRE ATT\&CK)
    \item \textbf{Other:} VULN\_DESC, PATCH/ADVISORY\_REF
\end{itemize}
This schema balances deterministic identifiers (CVE, CPE) with analyst-relevant context (products, TTPs), enabling downstream asset matching and ATT\&CK-driven triage~\cite{mitre2025attack, mitre2025cve}.

\subsection{Model Architecture}
The HEVA agent uses a hybrid approach:
\begin{itemize}
  \item \textbf{Regex matchers}: CVE, URL, IPv4, email (deterministic high precision).
  \item \textbf{spaCy entities}: pre-trained English model to propose span candidates.
  \item \textbf{Sentence embeddings}: \texttt{all-MiniLM-L6-v2} (384-dim) for sentence vectors.
  \item \textbf{Design-compatibility}: The pipeline is model-agnostic and can swap in RoBERTa/SecBERT checkpoints in future iterations without changing interfaces.
\end{itemize}

At inference, regex hits and model predictions are merged, validated, and linked to MITRE ATT\&CK techniques.

\paragraph{Vector Database Configuration.}
Sentence vectors are persisted in the Qdrant collection \texttt{ner\_vectors} using cosine similarity (vector size = 384).  
Each point stores \texttt{id}, \texttt{vector}, and payload fields such as \texttt{text}, \texttt{tokens}, \texttt{tags}, \texttt{length}, and \texttt{source}.

\subsection{Evaluation}
We evaluated CyberSage-HEVA on curated advisories and vendor bulletins.

\smallskip
\begin{table}[htbp]
\centering
\caption{Evaluation Results of HEVA on Curated Cybersecurity Advisories and Vendor Bulletins.}
\label{tab:heva-eval}
\begin{tabular}{@{}lccc@{}}
\toprule
Model Variant & Precision & Recall & Micro-F1 \\ \midrule
Regex-only baseline & 0.92 & 0.61 & 0.735 \\
spaCy-base & 0.88 & 0.79 & 0.820 \\
CyberSage-HEVA (hybrid) & \textbf{0.90} & \textbf{0.86} & \textbf{0.873} \\
\bottomrule
\end{tabular}
\end{table}

\noindent
\textit{Discussion.} Table~\ref{tab:heva-eval} shows the largest gains for \texttt{CVE\_ID} (+3.8 F1), \texttt{PRODUCT} (+6.1), and \texttt{ATTACK\_TECHNIQUE} (+7.4). 
Ablations confirmed the value of gazetteers (--2.1 F1 if removed), domain pretraining (--3.0), and CRF decoding (--0.8).

\subsection{Explainability and Assurance}
Explainability is embedded throughout the HEVA pipeline.  
Each extracted entity is logged with provenance metadata and confidence, ensuring reproducibility and analyst trust.

Each extracted entity is accompanied by:
\begin{itemize}
    \item Evidence trace (document ID, character offsets, regex hits, model confidence).
    \item Citation enforcement (linking CVEs to NVD or CISA KEV catalog \cite{cisa2025kev}) and exploitation likelihood features (EPSS \cite{first2025epss}).
    \item Confidence thresholds with human-in-the-loop escalation.
\end{itemize}
This ensures traceability, aligns with Responsible AI principles, and supports assurance requirements.

HEVA records the embedding model name, SHA-hash, and timestamp in every Qdrant payload (Listing~\ref{lst:agentB-payload}), supporting CyberSage’s Responsible-AI commitment and supporting reproducibility.

\subsection{Integration in CyberSage}
Outputs from HEVA feed into the Risk \& Triage Agent (C) as ``entity-aware embeddings that enable contextual retrieval and relevance scoring'' in Agent~C. During triage, Agent C queries this store via /search to retrieve semantically similar past advisories, grounding its risk prioritization logic.
The Assurance \& Explainability Agent (D) consumes HEVA outputs together with provenance metadata to generate transparent, analyst-facing summaries.
This establishes a continuous pipeline: normalization → extraction → retrieval → explanation.

\paragraph{Design Compatibility and Future Work.}
The prototype emphasizes throughput and reproducibility using spaCy + regex for NER.  
Future iterations can substitute domain-adapted transformers (e.g., RoBERTa or SecBERT) to improve recall while preserving the same interfaces and storage schema.

\noindent
In summary, HEVA transforms raw threat text into semantically indexed knowledge, bridging historical intelligence with modern LLM reasoning.  
This persistent vector memory underpins CyberSage’s retrieval-augmented triage and assurance workflow.

% ensure bib entries are included
\nocite{devlin2018bert, liu2019roberta, mitre2025attack, mitre2025cve}
